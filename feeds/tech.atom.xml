<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>MetaPipe - tech</title><link href="http://www.metapipe.com/" rel="alternate"></link><link href="localhost:8000/feeds/tech.atom.xml" rel="self"></link><id>http://www.metapipe.com/</id><updated>2017-03-28T08:31:00-06:00</updated><entry><title>The History of Linux in VFX and Animation</title><link href="http://www.metapipe.com/blog/posts/2017/03/28/history-of-linux-in-vfx-and-animation/" rel="alternate"></link><published>2017-03-28T08:31:00-06:00</published><updated>2017-03-28T08:31:00-06:00</updated><author><name>Aaron Estrada</name></author><id>tag:www.metapipe.com,2017-03-28:/blog/posts/2017/03/28/history-of-linux-in-vfx-and-animation/</id><summary type="html">&lt;p&gt;Nearly all high-end &lt;span class="caps"&gt;VFX&lt;/span&gt; shops use Linux. Why? In this jaunt down the rabbit hole we explore the history of &lt;span class="caps"&gt;C.G.&lt;/span&gt;I production and how we ended up where we are today. I also talk a little bit about why a studio might specifically choose Linux as a choice for large scale&amp;nbsp;production.&lt;/p&gt;</summary><content type="html">&lt;p&gt;People often seem surprised when I tell them that effectively all
high-end &lt;span class="caps"&gt;VFX&lt;/span&gt; and animation shops use
&lt;a href="https://en.wikipedia.org/wiki/Linux"&gt;Linux&lt;/a&gt;. Surely something like
Windows or &lt;span class="caps"&gt;OSX&lt;/span&gt; would be more convenient, right? Maybe so&amp;#8230; or maybe
not. As &lt;a href="/blog/author/ethan-estrada/"&gt;Ethan&lt;/a&gt;
mentioned in an &lt;a href="/blog/posts/2017/03/03/why-linux-for-vfx/"&gt;earlier post&lt;/a&gt;, Linux has some distinct advantages when
deployed at scale and in a pipeline vs traditional desktop operating
systems like Windows and &lt;span class="caps"&gt;OSX&lt;/span&gt;. Also, ignoring the history behind how
the high-end shops ended up where they are today would dismiss a
critical part of the overall story. Animation and &lt;span class="caps"&gt;VFX&lt;/span&gt; shops don’t only
use Linux for the advantages it offers today, there is a certain
amount of legacy behind the choice. Let’s look at the&amp;nbsp;history.&lt;/p&gt;
&lt;p&gt;Almost all of the larger &lt;span class="caps"&gt;C.G.&lt;/span&gt; shops started back in the Unix days,
some of them before Windows or Mac &lt;span class="caps"&gt;OS&lt;/span&gt; even existed. The earliest
&lt;span class="caps"&gt;C.G.&lt;/span&gt; studios were even using Lisp based machines and supercomputers
with custom OSes. Most of those studios no longer exist. Regardless,
the legacy of the older studios and the development of &lt;span class="caps"&gt;IT&lt;/span&gt; in general
impact how we do things&amp;nbsp;today.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;TRON&lt;/span&gt; was released in 1982, over 35 years ago! At the time, 3D
&lt;span class="caps"&gt;C.G.I.&lt;/span&gt; required a supercomputer to&amp;nbsp;render.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Image of Cray-1 Supercomputert" src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Cray_1_IMG_9126.jpg/640px-Cray_1_IMG_9126.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Pictured above is a &lt;a href="https://en.wikipedia.org/wiki/Cray-1"&gt;Cray-1&lt;/a&gt;
Supercomputer. One of these was used to render the &lt;span class="caps"&gt;C.G.I.&lt;/span&gt; in &lt;span class="caps"&gt;TRON&lt;/span&gt;. In
1977 this machine cost $5M - $8M depending on the options ordered. It
had 32MBytes of &lt;span class="caps"&gt;RAM&lt;/span&gt;, ran at 80 MHz and provided 160 &lt;span class="caps"&gt;MFLOPS&lt;/span&gt; of compute
power. To put that in perspective, assuming you have a relatively new
smartphone, the &lt;span class="caps"&gt;ARM&lt;/span&gt; &lt;span class="caps"&gt;CPU&lt;/span&gt; in your phone almost certainly provides over 1
GigaFlop. (That’s 1000 &lt;span class="caps"&gt;MFLOPS&lt;/span&gt;!) of computing power. It most likely has
1 or more &lt;span class="caps"&gt;GIGABYTES&lt;/span&gt; of &lt;span class="caps"&gt;RAM&lt;/span&gt;. Think about that. Your phone is more
powerful than the &lt;span class="caps"&gt;SUPERCOMPUTER&lt;/span&gt; (at the time) used to render
&lt;span class="caps"&gt;TRON&lt;/span&gt;. More amazingly, it’s likely more powerful than the computers
used to render even Jurassic Park!  Imagine how powerful modern &lt;span class="caps"&gt;PC&lt;/span&gt;
hardware is by&amp;nbsp;comparison.&lt;/p&gt;
&lt;p&gt;Of course, back when the hardware required to render 3D &lt;span class="caps"&gt;C.G.I.&lt;/span&gt; filled
a room and cost over $5 million, the desktop computers of the same era
were not even close to being up to the task. There was no 3D hardware
acceleration and the CPUs were not 32bit. Most did not have any
provision for calculating floating point math in hardware, which is a
critical feature for 3D rendering at any reasonable speed. &lt;span class="caps"&gt;RAM&lt;/span&gt; was
still incredibly expensive and the home computers of the era were only
8 or 16 bit. Even if the &lt;span class="caps"&gt;RAM&lt;/span&gt; were affordable, they couldn’t address
very much of it. They were essentially toys compared to the computers
used to do computer graphics at the time. Windows didn’t even exist
and neither did Mac &lt;span class="caps"&gt;OS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Anyone who has heard of
&lt;a href="https://en.wikipedia.org/wiki/Moore's_law"&gt;Moore&amp;#8217;s Law&lt;/a&gt; knows there
is an exponential pace of improvement in the state of the art in
computer science. Computer graphics requires large amounts of compute,
and for years, the cost of compute seemed high. After the era of the
mainframes and supercomputers for the production of &lt;span class="caps"&gt;C.G.&lt;/span&gt; came the era
of the minicomputer and &amp;#8220;workstation&amp;#8221;. These machines were still
expensive but at least they fit in the same room as the
artist. Relative to the mainframes and supercomputers they replaced
for doing &lt;span class="caps"&gt;C.G.&lt;/span&gt; work, they provided a very good performance per
dollar. Most of these machines ran Unix, and this was the era of early
&lt;span class="caps"&gt;C.G.&lt;/span&gt; blockbuster films like Jurassic Park, Terminator 2, and Toy
Story. There was a lot of growth in the &lt;span class="caps"&gt;C.G.&lt;/span&gt; industry in that
period. Not only was animation starting to shift over to computer
graphics, visual effects were driving the demand for photo-real &lt;span class="caps"&gt;C.G.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In parallel to the development of modern &lt;span class="caps"&gt;C.G.I.&lt;/span&gt; production, the .com
and &lt;span class="caps"&gt;WWW&lt;/span&gt; era of the Internet was maturing.  Unix was building a strong
foothold in the datacenter due to Sun, &lt;span class="caps"&gt;HP&lt;/span&gt;, &lt;span class="caps"&gt;DEC&lt;/span&gt; and &lt;span class="caps"&gt;SGI&lt;/span&gt; servers, which
all ran proprietary Unix variants. The demand for servers to feed the
growing demand for data delivered via the Internet drove the sales of
these computers. It was a less glamourous application of the
technology than C.G., but the higher volumes of machines being sold
helped drive the economy of scale so that the machines were more
affordable for &lt;span class="caps"&gt;C.G.&lt;/span&gt;&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;&lt;img alt="TUX, the Linux Mascot" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Tux.svg/280px-Tux.svg.png"&gt;&lt;/p&gt;
&lt;p&gt;By around 1995 Linux,
&lt;a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution"&gt;&lt;span class="caps"&gt;BSD&lt;/span&gt; Unix&lt;/a&gt;
and &lt;span class="caps"&gt;PC&lt;/span&gt; hardware were becoming mature enough relative to the established
Minicomputer and “Workstation” class machines that some adventurous
Internet server admins began putting parts of their workloads on &lt;span class="caps"&gt;PC&lt;/span&gt;
hardware. Graphic accelerator cards capable of running OpenGL became
available for the &lt;span class="caps"&gt;PC&lt;/span&gt;.  Folks in the &lt;span class="caps"&gt;VFX&lt;/span&gt; and animation business noticed
this. Home computers were no longer toy-like. They supported 32 bit
processors with integrated floating point units, could accept large
amounts of &lt;span class="caps"&gt;RAM&lt;/span&gt; and be networked via ethernet to connect with high
performance network attached storage. They were getting good enough to
compete with the workstation class machines and clusters of them
worked well for making inexpensive render&amp;nbsp;farms.&lt;/p&gt;
&lt;p&gt;The demand for home computers commoditized the &lt;span class="caps"&gt;PC&lt;/span&gt; and helped drive the
&lt;span class="caps"&gt;PC&lt;/span&gt; revolution. The economy of scale possible when selling commodity &lt;span class="caps"&gt;PC&lt;/span&gt;
hardware allowed for better R&amp;amp;D budgets than what the workstation and
minicomputer vendors could match. &lt;span class="caps"&gt;PC&lt;/span&gt; hardware was catching up with
workstation class hardware and actually started to surpass it in many
ways.  By around 1997, when Linux had begun to really mature,
commodity &lt;span class="caps"&gt;PC&lt;/span&gt; hardware had begun to outpace the minicomputer and
&amp;#8220;workstation&amp;#8221; class stuff from the likes of Sun, &lt;span class="caps"&gt;SGI&lt;/span&gt;, &lt;span class="caps"&gt;HP&lt;/span&gt; and &lt;span class="caps"&gt;IBM&lt;/span&gt;.  The
new &lt;span class="caps"&gt;PC&lt;/span&gt; hardware was sufficiently faster (per dollar spent) than the
&amp;#8220;workstation&amp;#8221; and &amp;#8220;minicomputer&amp;#8221; class stuff from the legacy vendors
that the economics could no longer be ignored. Running Linux on the
new &lt;span class="caps"&gt;PC&lt;/span&gt; hardware was the obvious choice because all the custom software
(after re-compilation) and automation scripts they had created over
the years for Unix would just keep working as usual. Porting the
custom code over to a &lt;span class="caps"&gt;NON&lt;/span&gt;-Unix-Like &lt;span class="caps"&gt;OS&lt;/span&gt; would have been a huge chore
but tweaking it for Linux (which is mostly Posix compliant) was a much
less difficult task. Plus, all the artists at the shops knew and
trusted Unix-like systems. At the time, Windows was for playing video
games and doing spreadsheets, not making &lt;span class="caps"&gt;C.G.&lt;/span&gt; for feature films.  A
little bit of trivia&amp;#8230; I worked at one shop that even still used &lt;span class="caps"&gt;CSH&lt;/span&gt;
(rather than the more modern Bash shell or a more robust scripting
language like Python) due to still having so much automation that was
still dependent on &lt;span class="caps"&gt;CSH&lt;/span&gt;. Legacy support was definitely part of the
equation when making the switch to Linux from proprietary Unix&amp;nbsp;variants.&lt;/p&gt;
&lt;p&gt;So, that’s a quick history of how we ended up where we are. But does
that mean we only use Linux today because we are stuck supporting some
old legacy code from the stone ages? Far from it! I have to agree with
&lt;a href="/blog/posts/2017/03/03/why-linux-for-vfx/"&gt;Ethan&lt;/a&gt; that even
today, Unix-like OSes are more suitable for large scale deployments
and automation. There is a reason nearly the entire Internet and
your smartphone run Linux or some flavor of Unix. What works at scale
for the Internet of course also works at scale for
&lt;span class="caps"&gt;C.G.&lt;/span&gt; production. The standard system shell and file system semantics
alone completely smoke anything on Windows.  Scripting languages like
Python are first class citizens and there is a wealth of Free Open
Source Software available to help address just about any conceivable
need. Basically, with Linux you have some great building blocks for
creating large systems. Plus, the larger the render farm, the more you
save when running Linux vs Windows (While &lt;span class="caps"&gt;OSX&lt;/span&gt; is based on Unix, it
isn&amp;#8217;t an option since Apple doesn&amp;#8217;t license the &lt;span class="caps"&gt;OS&lt;/span&gt; alone. It’s not
possible to run &lt;span class="caps"&gt;OSX&lt;/span&gt; in the cloud.) Netbooting Linux is more straight
forward than Windows also, which makes managing huge fleets of
machines&amp;nbsp;easier.&lt;/p&gt;
&lt;p&gt;Linux supports most of the high end &lt;span class="caps"&gt;DCC&lt;/span&gt; applications a &lt;span class="caps"&gt;C.G.&lt;/span&gt; artist
might want to use but a few notable examples, like Photoshop, are
missing. At present, this is really the only negative of using Linux
vs using something else. Of course, the same could be said for any
&lt;span class="caps"&gt;OS&lt;/span&gt;. There is always some killer app missing from any given
platform. (Final Cut is missing from Windows, &lt;span class="caps"&gt;3DS&lt;/span&gt; Max is missing on
&lt;span class="caps"&gt;OSX&lt;/span&gt;,&amp;nbsp;etc.)&lt;/p&gt;
&lt;p&gt;If you are an aspiring &lt;span class="caps"&gt;VFX&lt;/span&gt; artist I recommend you learn enough Linux
to at least get around in it. Consider learning Python and possibly
some more advanced shell scripting. Assuming your other skills are
solid, a working knowledge of Linux will help you stand out as an
artist &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; &lt;span class="caps"&gt;TD&lt;/span&gt;.&lt;/p&gt;</content><category term="Linux"></category><category term="tech"></category><category term="explainer"></category></entry><entry><title>Why use Linux for VFX?</title><link href="http://www.metapipe.com/blog/posts/2017/03/03/why-linux-for-vfx/" rel="alternate"></link><published>2017-03-03T09:23:54-07:00</published><updated>2017-03-03T09:23:54-07:00</updated><author><name>Ethan Estrada</name></author><id>tag:www.metapipe.com,2017-03-03:/blog/posts/2017/03/03/why-linux-for-vfx/</id><summary type="html">&lt;!-- A version of this content was first posted on: https://www.quora.com/In-the-VFX-industry-why-would-some-studios-use-UNIX/answer/Ethan-Estrada?srid=Dmy6 --&gt;

&lt;p&gt;When this question is asked, the question between the lines is really
&amp;#8220;Why don&amp;#8217;t they use Windows?&amp;#8221; since the only other real contender
outside Linux is Apple &lt;span class="caps"&gt;OSX&lt;/span&gt;, which itself is based on &lt;span class="caps"&gt;BSD&lt;/span&gt; Unix. For
most intents and purposes, Unix and Linux are pretty&amp;nbsp;interchangeable.&lt;/p&gt;
&lt;p&gt;Only very small …&lt;/p&gt;</summary><content type="html">&lt;!-- A version of this content was first posted on: https://www.quora.com/In-the-VFX-industry-why-would-some-studios-use-UNIX/answer/Ethan-Estrada?srid=Dmy6 --&gt;

&lt;p&gt;When this question is asked, the question between the lines is really
&amp;#8220;Why don&amp;#8217;t they use Windows?&amp;#8221; since the only other real contender
outside Linux is Apple &lt;span class="caps"&gt;OSX&lt;/span&gt;, which itself is based on &lt;span class="caps"&gt;BSD&lt;/span&gt; Unix. For
most intents and purposes, Unix and Linux are pretty&amp;nbsp;interchangeable.&lt;/p&gt;
&lt;p&gt;Only very small boutique shops and freelancers use &lt;span class="caps"&gt;MS&lt;/span&gt; Windows
exclusively, and I have found that this confounds young artists new to
the industry as well as veterans who have only ever worked at smaller
shops. The ease of use and ease of intitial set up of &lt;span class="caps"&gt;MS&lt;/span&gt; Windows seem
like home runs to a lot of artists, and so they are left scratching
their heads. While I could focus on the historical reasons for Unix
use , I would rather talk specifically about a few technical reasons
why building a pipeline on Linux/Unix is relatively easy, whereas
doing the same on Windows is downright painful, if not outright
unfeasible. Perhaps I will encourage &lt;a href="/team/"&gt;Aaron&lt;/a&gt;
to make a post about the historical set of reasons for using
Unix. When I say &amp;#8220;Unix&amp;#8221; from here on out, it also includes Linux,
unless otherwise&amp;nbsp;stated.&lt;/p&gt;
&lt;h3&gt;1. Support for symbolic&amp;nbsp;links&lt;/h3&gt;
&lt;p&gt;Unix has had solid support for symbolic links for decades. Windows has
barely added this in Vista, and even then it is still not very good
(and, no, shortcuts are &lt;span class="caps"&gt;NOT&lt;/span&gt; the same thing as symbolic links). Why
would you want symbolic links you ask? Well, let&amp;#8217;s look at a toy
pipeline for the answer (this will be massively oversimplified and is
a poor pipeline model, but works for demonstration). Let&amp;#8217;s say our
system is very simple: for a given shot in a show, we have a
directory that holds all of our files (scene, geometry, textures, the
current version of the plates from the client, etc.). This directory
is a version number. So our directory looks somthing like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/proj/seq/shot
    &lt;span class="m"&gt;001&lt;/span&gt;
    &lt;span class="m"&gt;002&lt;/span&gt;
    &lt;span class="m"&gt;003&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Every time we want to version up, we copy the latest version and
renumber it. Dandy! Now what is the problem that happens when our
scene file (let&amp;#8217;s say it is Maya) is versioned up from v2 to v3? All
the file paths still point to v2! Now your supervisor is going to be
angry because you didn&amp;#8217;t update your geometry of that one creature for
your scene. &amp;#8220;But I did, I swear I did!&amp;#8221; you screech in
desperation. Well, it doesn&amp;#8217;t matter that you updated the geometry
file in version 3, because your scene file was still pointed to the
version 2 geometry file. This may seem like an easy fix to do by hand,
but it gets irritating once you are on version 50 and still doing it
over and over and over again. Also, once you are referencing dozens or
hundreds of things into your scene, it simply becomes unfeasible to do
by hand&amp;nbsp;anymore.&lt;/p&gt;
&lt;p&gt;So, what is a simple solution? We write a simple script for versioning
up. It does the copy operation we previously did by hand, but it also
adds one more thing: a symbolic link called &amp;#8220;current&amp;#8221;. So now our
directory looks like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/proj/seq/shot
    &lt;span class="m"&gt;001&lt;/span&gt;
    &lt;span class="m"&gt;002&lt;/span&gt;
    &lt;span class="m"&gt;003&lt;/span&gt;
    current -&amp;gt; &lt;span class="m"&gt;003&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And we always work out of current. We make sure all of our referenced
file paths point through current as well. If we need to go back to a
previous version, we make sure to change the &amp;#8220;current&amp;#8221; sym link to
point there first. We would probably do this through some sort of &amp;#8220;job
in&amp;#8221; script so, again, we wouldn&amp;#8217;t need to do this by hand each&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Again, this is a simplified example, but these sorts of things happen
all the time in a real production&amp;nbsp;pipeline.&lt;/p&gt;
&lt;h3&gt;2. Atomic file&amp;nbsp;renames&lt;/h3&gt;
&lt;p&gt;By atomic, I mean the operation either fails or succeeds. There is no
in between state; the file can&amp;#8217;t be partially renamed. Along with
this, renames will overwrite other existing files. This is a dual
edged sword since you do need to be careful, but you have the power to
do so when you need&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Lets use python to show this example. In Unix systems, if I want to
rename a file, all I do is&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="c1"&gt;# I don&amp;#39;t care if the destination file exists, just clobber it&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;some_temp_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;final_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This previous command will only fail if I don&amp;#8217;t have access to the
file system where these file(s) exist, or I don&amp;#8217;t have permission to
modify them. But, barring that, it will&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;If you try to rename over a file that already exists in Windows, it
will fail with an error, no matter what. Thus, renames cannot ever be
truly atomic. The only hope on windows is to do one of the following
(neither of which is very&amp;nbsp;good):&lt;/p&gt;
&lt;p&gt;First&amp;nbsp;solution:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shutil&lt;/span&gt;
&lt;span class="c1"&gt;# uh-oh, our file is corrupt if we fail partway through&lt;/span&gt;
&lt;span class="n"&gt;shutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;some_temp_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;final_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Second&amp;nbsp;solution:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="c1"&gt;# I sure hope this OTHER temp file doesn&amp;#39;t already exist&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;final_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;some_other_temp_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# someone else could still recreate this file before I have a chance to rename it.&lt;/span&gt;
&lt;span class="c1"&gt;# Better known as a race condition. In windows, it is unavoidable in this situation.&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;some_temp_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;final_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;some_other_temp_file.obj&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;3. Powerful built in file&amp;nbsp;permissions&lt;/h3&gt;
&lt;p&gt;Yes, yes, windows has solutions for this using access lists and other
such things when doing network logins, but they are far removed from
the average or even the technical user, which is most &lt;span class="caps"&gt;VFX&lt;/span&gt;
artists. Also, they are not a built in part of the &lt;span class="caps"&gt;OS&lt;/span&gt;. Windows was not
built with networking in mind; it was bolted on after the fact and it
shows. Windows was not built as a multi-user &lt;span class="caps"&gt;OS&lt;/span&gt;; again, bolted on
after the fact and it shows. Unix has always been multi-user since the
very beginning. Networking became a part of Unix before Windows (or &lt;span class="caps"&gt;MS&lt;/span&gt;
&lt;span class="caps"&gt;DOS&lt;/span&gt; for that matter) even existed. Thus, both are extremely mature and
fairly&amp;nbsp;standardized.&lt;/p&gt;
&lt;h3&gt;4. Mount points for networked drives can be&amp;nbsp;anywhere&lt;/h3&gt;
&lt;p&gt;On windows they need to be on a lettered drive, or using a network
share mount. On Unix, you never need to even know it is a network
mount. Thus it can easily be swapped out later without totally
breaking things. With pipelines that are ever evolving, but still need
to maintain some backwards compatibility, this is a huge boon. As a
case in point, during university, I worked at a small shop on
campus that used Windows. At one point, the &lt;span class="caps"&gt;IT&lt;/span&gt; folks at the shop decided we all needed
to move from the &lt;code&gt;S:&lt;/code&gt; drive to the &lt;code&gt;K:&lt;/code&gt; drive for our network
shares. Needless to say, pretty much all of our scene files&amp;nbsp;broke.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;There are other things that make Unix easier to work with in
production pipelines, but the above are the biggest ones
&lt;span class="caps"&gt;IMHO&lt;/span&gt;. Hopefully some of the appeal is a bit clearer to you now than it
was before. If not, send an email to
&lt;a href="mailto:info@metapipe.com"&gt;info@metapipe.com&lt;/a&gt;. The message should make
its way to me and I&amp;#8217;ll do what I can to answer your&amp;nbsp;questions.&lt;/p&gt;</content><category term="Linux"></category><category term="tech"></category><category term="explainer"></category></entry><entry><title>So, what is a virtual machine anyway?</title><link href="http://www.metapipe.com/blog/posts/2017/03/02/what-is-a-virtual-machine/" rel="alternate"></link><published>2017-03-02T10:25:56-07:00</published><updated>2017-03-02T10:25:56-07:00</updated><author><name>Ethan Estrada</name></author><id>tag:www.metapipe.com,2017-03-02:/blog/posts/2017/03/02/what-is-a-virtual-machine/</id><summary type="html">&lt;p&gt;We use the term &amp;#8220;Virtual Machine&amp;#8221; (or &amp;#8220;&lt;span class="caps"&gt;VM&lt;/span&gt;&amp;#8221;) a lot here at MetaPipe,
but you might not know what that means. This short explaination should
help clear things up a&amp;nbsp;bit.&lt;/p&gt;
&lt;p&gt;First, the obtuse, opaque answer: a virtual machine is a computer
within a computer. But I figure that answer …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We use the term &amp;#8220;Virtual Machine&amp;#8221; (or &amp;#8220;&lt;span class="caps"&gt;VM&lt;/span&gt;&amp;#8221;) a lot here at MetaPipe,
but you might not know what that means. This short explaination should
help clear things up a&amp;nbsp;bit.&lt;/p&gt;
&lt;p&gt;First, the obtuse, opaque answer: a virtual machine is a computer
within a computer. But I figure that answer is about as clear as mud,
right? So let&amp;#8217;s try using something else that we can relate to. You
can think of virtual machines as something like a russian nesting
doll. Or better yet, you can think of virtual machines like
Christopher Nolan&amp;#8217;s &lt;em&gt;Inception&lt;/em&gt;. But unlike &lt;em&gt;Inception&lt;/em&gt;, you won&amp;#8217;t
need to pretend like you know what the heck is going on.&amp;nbsp;¯\_(ツ)_/¯&lt;/p&gt;
&lt;!-- image original URL: http://dazedimg.dazedgroup.netdna-cdn.com/786/azure/dazed-prod/1120/2/1122563.jpg --&gt;

&lt;p&gt;&lt;img src="/static/img/blog/Inception_top.jpg" width="300"&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.dazeddigital.com/artsandculture/article/24949/1/christopher-nolan-explains-the-spinning-top-in-inception"&gt;Originally posted by&amp;nbsp;Dazed&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So in the same way that &lt;em&gt;Inception&lt;/em&gt; hangs on the idea of a dream
within a dream, virtual machines hang on the idea of a computer within
a computer.  When people talk about a virtual machine what they
generally mean is a piece of software that exposes only certain parts
of the underlying hardware to a &amp;#8220;guest&amp;#8221; operating system (or &lt;span class="caps"&gt;OS&lt;/span&gt;).  By
doing this, a computer running, say Linux, can simultaneously run
Microsoft Windows as an application on the desktop. All the features
of Microsoft Windows are then available to you, without the need to
run a separate physical machine or needing to reboot your system into
another Operating&amp;nbsp;System.&lt;/p&gt;
&lt;p&gt;Because virtual machine software only exposes limited parts of the
underlying hardware, it wasn&amp;#8217;t until recently that advanced graphics
workloads could be run on a virtual machine. The &lt;span class="caps"&gt;VM&lt;/span&gt; software running
on the host operating system would only show the guest &lt;span class="caps"&gt;OS&lt;/span&gt; the few
parts that were safe to expose. For instance, CPUs from Intel and &lt;span class="caps"&gt;AMD&lt;/span&gt;
have long supported special extensions to make &lt;span class="caps"&gt;VM&lt;/span&gt; computing both safe
and fast. Within the past few years, &lt;span class="caps"&gt;GPU&lt;/span&gt; makers like Nvidia and
&lt;span class="caps"&gt;AMD&lt;/span&gt;/&lt;span class="caps"&gt;ATI&lt;/span&gt; have done the same with their datacenter video cards, adding specific
extensions to make exposing the &lt;span class="caps"&gt;GPU&lt;/span&gt; to &lt;span class="caps"&gt;VM&lt;/span&gt; guests both safe and
fast. With these new cards available, the last puzzle pieces have now
been put in place to virtualize all the most critical aspects of
general purpose&amp;nbsp;computing.&lt;/p&gt;
&lt;p&gt;So, now we have defined what a virtual machine is, but what is the
point of virtual computing? At first glance, it just sounds like a way
to further complicate the Gordian Knot that is modern computing. But
never fear; there are some distinct advantages to virtual computing
that make it well worth my (and your) time to understand and
use. Let&amp;#8217;s enumerate them as bullet&amp;nbsp;points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Virtual Machines are software.&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;This doesn&amp;#8217;t seem like much of a point, but I promise that it
is.  As we go down this list I hope you&amp;#8217;ll see&amp;nbsp;why.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software is easier to modify than hardware.&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Modifying hardware takes months or years of design and
fabrication.  Software on the other hand, can be modified,
recompiled and delivered in as little as minutes. When software
has a bug, it can be fixed and turned around in relatively little
time. When hardware has a bug, companies often need to go back to
the drawing board to fix the problem next&amp;nbsp;time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software is easier to control programmatically than hardware.&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Software can often have a simple scripting interface that makes
it easy to control from the outside, like a marionette with
strings. With raw hardware, it can be difficult to externally
script things like &amp;#8220;turn on&amp;#8221;, &amp;#8220;turn off&amp;#8221;, &amp;#8220;grab another harddrive,
install it, get the required drivers and then mount it so that the
operating system can see it.&amp;#8221; You get the&amp;nbsp;picture.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software is easier to &amp;#8220;move&amp;#8221; than hardware.&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;To move a piece of physical hardware, you need to, well,
physically move it. To move software (or in our case, a virtual
machine), you simply need to copy some files around. Much easier,
much less error prone, and much easier to repeat over and&amp;nbsp;over.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software can be &amp;#8220;ephemeral&amp;#8221; at almost no cost. Not so with
  hardware.&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;We can&amp;#8217;t all go around smashing our hardware at the end of each
performance like Jimi Hendrix. Or can we?  Using virtual machines,
we can create computers that can be created from scratch almost as
quickly as it takes to boot up the machine. In fact, that is
exactly what we try to do at MetaPipe: each time you start a
machine, it is completely fresh.
&lt;!-- image original URL: http://reverb-res.cloudinary.com/image/upload/q_10/v1400774613/Hendrix_zitz9h.gif --&gt;
&lt;p&gt;&lt;img src="/static/img/blog/Hendrix_smash.gif" width="300"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://reverb.com/news/10-greatest-guitar-carnage-moments"&gt;Originally posted by&amp;nbsp;Reverb&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And this (&lt;code&gt;#shamelessplug&lt;/code&gt;) is where &lt;a href="/"&gt;MetaPipe&lt;/a&gt;
comes into the picture.  We are trying to democratize Virtual Machine
computing and make it easy and accessible to everyone, most especially
to creative professionals who have some of the most extreme computing
needs on the face of the&amp;nbsp;planet.&lt;/p&gt;</content><category term="tech"></category><category term="explainer"></category></entry></feed>